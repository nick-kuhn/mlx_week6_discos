# Default configuration for fine-tuning summarization model
# This config mirrors the current argparse defaults in train.py

# Model configuration
model:
  name: "Qwen/Qwen3-0.6B-Base"
  checkpoint_dir: "checkpoints"

# Training hyperparameters
training:
  num_epochs: 1
  batch_size: 8
  eval_batch_size: 8
  gradient_accumulation_steps: 2
  learning_rate: 2e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  lr_scheduler: "cosine"  # Options: cosine, linear
  use_amp: true

# Data configuration
data:
  train_path: "CarperAI/openai_summarize_tldr"
  val_path: "CarperAI/openai_summarize_tldr"
  num_workers: 0  # Set to 0 for Windows compatibility

# Logging and monitoring
logging:
  use_wandb: true
  wandb_project: "summarization-finetuning"
  run_name: null  # Auto-generated if null
  log_freq: 50
  eval_freq: 500
  max_eval_batches: 100
  upload_checkpoints: true
  checkpoint_upload_freq: 2000
  delete_after_upload: true
  verbose_evals: false
  reward_evaluation: false

# Resume training
resume:
  resume_from_checkpoint: null

# Advanced settings
advanced:
  # LoRA configuration (now configurable)
  lora:
    r: 4                    # Reduced from 8 for more conservative updates
    alpha: 8                # Reduced from 32 (alpha=2*r for scaling factor of 2.0)
    dropout: 0.1            # Increased from 0.05 for better regularization
    bias: "none"
    target_modules: ["q_proj", "v_proj"]  # Only attention query/value projections
  
  # Mixed precision settings
  mixed_precision:
    enabled: true
    dtype: "fp16"  # Options: fp16, bf16
  
  # Memory optimization
  memory:
    gradient_checkpointing: false
    cleanup_frequency: 20  # Steps between cache cleanup
    tensor_cache_cleanup_freq: 500
  
  # Generation settings for evaluation
  generation:
    max_new_tokens: 100
    do_sample: true
    temperature: 0.7
    top_p: 0.9
    repetition_penalty: 1.1